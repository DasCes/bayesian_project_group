{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee9c70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import erf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4803d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    mean_used = df['S2_val'].tolist()\n",
    "    result    = df['Decision (S1>S2)'].tolist()\n",
    "    data_tuple = (result, mean_used)\n",
    "    return data_tuple\n",
    "\n",
    "def data_var2(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    var2 = df['S2_std'].to_numpy()\n",
    "    var2 = pd.unique(var2)     # valeurs uniques de S2_std\n",
    "    return list(var2)\n",
    "\n",
    "def psycometrique(data_tuple, var2, block_size=1500, big_blocs=11):\n",
    "    \"\"\"\n",
    "    Reconstruit les moyennes par bloc comme dans ton code :\n",
    "    - true_array_result[j][k] = P(1) pour le j-ième var2, k-ième S2_val\n",
    "    - true_array_mean_used[j][k] = S2_val moyenne correspondante\n",
    "    \"\"\"\n",
    "    result, mean_used = data_tuple\n",
    "    true_array_mean_used = []\n",
    "    true_array_result    = []\n",
    "\n",
    "    size_one_block = block_size * big_blocs  # nb essais par courbe (11 x 200)\n",
    "\n",
    "    for j in range(len(var2)):\n",
    "        array_mean_result = []\n",
    "        array_mean_used   = []\n",
    "        for i in range(0, size_one_block, block_size):\n",
    "            # bloc de result\n",
    "            block_r = result[size_one_block*j + i : size_one_block*j + i + block_size]\n",
    "            mean_r  = sum(block_r) / len(block_r)\n",
    "            array_mean_result.append(mean_r)\n",
    "\n",
    "            # bloc de mean_used\n",
    "            block_m = mean_used[size_one_block*j + i : size_one_block*j + i + block_size]\n",
    "            mean_m  = sum(block_m) / len(block_m)\n",
    "            array_mean_used.append(mean_m)\n",
    "\n",
    "        true_array_result.append(array_mean_result)\n",
    "        true_array_mean_used.append(array_mean_used)\n",
    "\n",
    "    return true_array_result, true_array_mean_used\n",
    "\n",
    "def build_targets_from_csv(file_path, block_size=1500, big_blocs=11):\n",
    "    \"\"\"\n",
    "    Construit :\n",
    "      - target[(mu2, std2)] = P_empirique(réponse=1)\n",
    "      - mus_test : liste ordonnée des S2_val utilisés\n",
    "      - vars_test : liste ordonnée des S2_std utilisés\n",
    "    à partir de ton CSV.\n",
    "    \"\"\"\n",
    "    data_tuple = reading_csv(file_path)\n",
    "    var2_list  = data_var2(file_path)           # S2_std uniques\n",
    "    array_mean_result, array_mean_used = psycometrique(\n",
    "        data_tuple, var2_list,\n",
    "        block_size=block_size,\n",
    "        big_blocs=big_blocs\n",
    "    )\n",
    "\n",
    "    target = {}\n",
    "    # on suppose que les S2_val sont les mêmes pour chaque var2\n",
    "    mus_test = array_mean_used[0]\n",
    "    vars_test = var2_list\n",
    "\n",
    "    for j, std2 in enumerate(var2_list):\n",
    "        for k, mu2 in enumerate(array_mean_used[j]):\n",
    "            p_emp = array_mean_result[j][k]\n",
    "            target[(mu2, std2)] = p_emp\n",
    "\n",
    "    return target, mus_test, vars_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae1f4a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(-10.0, np.int64(0)): 1.0, (-8.0, np.int64(0)): 1.0, (-6.0, np.int64(0)): 1.0, (-4.0, np.int64(0)): 1.0, (-2.0, np.int64(0)): 0.9993333333333333, (0.0, np.int64(0)): 0.4746666666666667, (2.0, np.int64(0)): 0.005333333333333333, (4.0, np.int64(0)): 0.0, (6.0, np.int64(0)): 0.0, (8.0, np.int64(0)): 0.0, (10.0, np.int64(0)): 0.0, (-10.0, np.int64(2)): 1.0, (-8.0, np.int64(2)): 0.9986666666666667, (-6.0, np.int64(2)): 0.9953333333333333, (-4.0, np.int64(2)): 0.9566666666666667, (-2.0, np.int64(2)): 0.8313333333333334, (0.0, np.int64(2)): 0.5873333333333334, (2.0, np.int64(2)): 0.346, (4.0, np.int64(2)): 0.11333333333333333, (6.0, np.int64(2)): 0.04133333333333333, (8.0, np.int64(2)): 0.008, (10.0, np.int64(2)): 0.0, (-10.0, np.int64(4)): 0.9526666666666667, (-8.0, np.int64(4)): 0.9266666666666666, (-6.0, np.int64(4)): 0.8886666666666667, (-4.0, np.int64(4)): 0.8313333333333334, (-2.0, np.int64(4)): 0.73, (0.0, np.int64(4)): 0.642, (2.0, np.int64(4)): 0.536, (4.0, np.int64(4)): 0.454, (6.0, np.int64(4)): 0.35533333333333333, (8.0, np.int64(4)): 0.25066666666666665, (10.0, np.int64(4)): 0.16466666666666666, (-10.0, np.int64(6)): 0.8573333333333333, (-8.0, np.int64(6)): 0.828, (-6.0, np.int64(6)): 0.808, (-4.0, np.int64(6)): 0.7493333333333333, (-2.0, np.int64(6)): 0.712, (0.0, np.int64(6)): 0.6633333333333333, (2.0, np.int64(6)): 0.6, (4.0, np.int64(6)): 0.5666666666666667, (6.0, np.int64(6)): 0.494, (8.0, np.int64(6)): 0.458, (10.0, np.int64(6)): 0.398, (-10.0, np.int64(8)): 0.786, (-8.0, np.int64(8)): 0.7686666666666667, (-6.0, np.int64(8)): 0.7473333333333333, (-4.0, np.int64(8)): 0.7273333333333334, (-2.0, np.int64(8)): 0.6913333333333334, (0.0, np.int64(8)): 0.6766666666666666, (2.0, np.int64(8)): 0.65, (4.0, np.int64(8)): 0.632, (6.0, np.int64(8)): 0.5733333333333334, (8.0, np.int64(8)): 0.5633333333333334, (10.0, np.int64(8)): 0.514}\n"
     ]
    }
   ],
   "source": [
    "target, mus_test, vars_test = build_targets_from_csv('C:\\\\Users\\\\gabri\\\\Desktop\\\\bayesian\\\\experiment_results_1500.csv') # before experiment_results_test.csv \n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b599c9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.536\n"
     ]
    }
   ],
   "source": [
    "mus_test  = [-10,-8,-6,-4,-2,0,2,4,6,8,10]\n",
    "vars_test = [0,2,4,6,8]\n",
    "mu1,mu2 = 0 , 2\n",
    "var1,var2 = 0.2 , 4\n",
    "print(target[(mu2, var2)])  # exemple d'accès à une valeur cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb1d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfinv\n",
    "\n",
    "def inverse_phi(x):\n",
    "    \"\"\" Approximation de l'inverse de la fonction de répartition normale centrée réduite \"\"\"\n",
    "    return np.sqrt(2) * erfinv(2 * x - 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
